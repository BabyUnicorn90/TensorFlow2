{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = tf.random.uniform([1], 0, 1)    \n",
    "#random.uniform( [배열형태], 랜덤값의 최솟값, 랜덤값의 최댓값 )  <-- 인자로 dtype, name 등 추가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.17573607], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[0.31575614, 0.59793036],\n",
       "       [0.52561252, 0.81956675]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2 = tf.random.uniform([2, 2], 0, 1, dtype=tf.dtypes.float64)\n",
    "rand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand2.shape\n",
    "rand2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.57506084, 0.6297666 , 0.7244046 , 0.7621589 ], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand3= tf.random.uniform([4], 0, 1)\n",
    "rand3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **뉴런만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2725548088590048\n",
      "99 -0.08199760656834773 0.08199760656834773\n",
      "199 -0.04626696103821343 0.04626696103821343\n",
      "299 -0.03200138464986776 0.03200138464986776\n",
      "399 -0.02440024700051744 0.02440024700051744\n",
      "499 -0.01969476285274087 0.01969476285274087\n",
      "599 -0.01650065237874846 0.01650065237874846\n",
      "699 -0.014192833499124995 0.014192833499124995\n",
      "799 -0.012448387359154227 0.012448387359154227\n",
      "899 -0.011084002812361148 0.011084002812361148\n",
      "999 -0.00998801554741427 0.00998801554741427\n"
     ]
    }
   ],
   "source": [
    "#[1] 활성화함수 만들기: sigmoid\n",
    "#활성화함수: sigmoid, reLU\n",
    "\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "#[2] 뉴런의 입력과 출력 정의하기\n",
    "#입력이 1일 때 기대출력이 0이 되는 뉴런: \n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "w = tf.random.normal([1], 0, 1)      #<------ 뉴런! \n",
    "#random.normal(): 정규분포로부터 난수값 반환 \n",
    "#random.normal( [반환값 텐서의 형태], 정규분포의 평균(0), 정규분포의 표준편차(1) )\n",
    "output = sigmoid(x * w)\n",
    "\n",
    "print(output)\n",
    "\n",
    "#error 구하기\n",
    "y_error = y - output\n",
    "\n",
    "#[3]내가 원하는 값(y)이 나오도록 뉴런(가중치) 조절하기: 경사하강법(Gradient Descent)\n",
    "#경사하강법: 가중치(w)에 (입력 * 학습률 * 에러)를 더해주는 것 \n",
    "#  --손실곡선의 기울기. 손실곡선을 미분한 다음 그 값을 이용해서 가중치가 손실이 가장 낮아지는 지점에 도달하도록 반복 계산\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error     #학습률: 0.1\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.5 0.5\n",
      "199 0.5 0.5\n",
      "299 0.5 0.5\n",
      "399 0.5 0.5\n",
      "499 0.5 0.5\n",
      "599 0.5 0.5\n",
      "699 0.5 0.5\n",
      "799 0.5 0.5\n",
      "899 0.5 0.5\n",
      "999 0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)\n",
    "        \n",
    "#[!] 결과값이 같다: 0을 곱하기 때문에 w가 변하지 않는다. \n",
    "# =한 값만 나온다.\n",
    "# =편향된 값만 나온다. \n",
    "#-----> 편향된 값만 나오는 것을 방지하기 위해 '편향(bias)'를 뉴런에 적용시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.07094603777373032 0.9290539622262697\n",
      "199 0.04241546691684117 0.9575845330831588\n",
      "299 0.03008673251101679 0.9699132674889832\n",
      "399 0.023263438441313067 0.9767365615586869\n",
      "499 0.018944290987143675 0.9810557090128563\n",
      "599 0.015969077105946083 0.9840309228940539\n",
      "699 0.013796927970618045 0.986203072029382\n",
      "799 0.012142290319060445 0.9878577096809396\n",
      "899 0.010840382165573259 0.9891596178344267\n",
      "999 0.0097895598467298 0.9902104401532702\n"
     ]
    }
   ],
   "source": [
    "#입력이 0일 때 기대출력이 1이 되는 뉴런의 학습에 편향 더하기:\n",
    "x = 0\n",
    "y = 1\n",
    "w = tf.random.normal([1], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)    #편향으로는 보편적으로 1을 사용한다. \n",
    "\n",
    "for i in range(1000):\n",
    "    output = sigmoid(x * w + 1 * b)\n",
    "    error = y - output\n",
    "    w = w + x * 0.1 * error\n",
    "    b = b + 1 * 0.1 * error\n",
    "    \n",
    "    if i % 100 == 99:\n",
    "        print(i, error, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **첫 번째 신경망 네트워크: AND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True는 1 False는 0 을 사용하자\n",
      "199 -0.10559216756567036\n",
      "399 -0.06401694892877259\n",
      "599 -0.04580654745801787\n",
      "799 -0.035561061855791457\n",
      "999 -0.029009439070860392\n",
      "1199 -0.02446909690814023\n",
      "1399 -0.02114209357755427\n",
      "1599 -0.018601673845089244\n",
      "1799 -0.01660027969979116\n",
      "1999 -0.014983499541940061\n",
      "X: [1 1] Y: [1] Output: 0.9650203207486281\n",
      "X: [1 0] Y: [0] Output: 0.024789051977628287\n",
      "X: [0 1] Y: [0] Output: 0.024864379094507314\n",
      "X: [0 0] Y: [0] Output: 2.3493239256199956e-05\n"
     ]
    }
   ],
   "source": [
    "#두 개의 입력을 받는 AND 연산 \n",
    "#입력값 두개가 모두 참일때만 참 반환\n",
    "\n",
    "#cf. True, False로 어떤 수를 사용해야할까? (딥러닝의 주요 입력값은 int 또는 float!)\n",
    "print('True는', int(True),\n",
    "     'False는', int(False),\n",
    "     '을 사용하자')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [0], [0], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#AND 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **두 번째 신경망 네트워크: OR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.048283128196595304\n",
      "399 -0.025528192246457304\n",
      "599 -0.01723723739441667\n",
      "799 -0.01296647707506321\n",
      "999 -0.010372994898457708\n",
      "1199 -0.008635228027301337\n",
      "1399 -0.007391663459512796\n",
      "1599 -0.0064579576258035065\n",
      "1799 -0.005732655204398401\n",
      "1999 -0.005151416835960616\n",
      "X: [1 1] Y: [1] Output: 0.9999972026832725\n",
      "X: [1 0] Y: [1] Output: 0.9897886904430638\n",
      "X: [0 1] Y: [1] Output: 0.9897608545963603\n",
      "X: [0 0] Y: [0] Output: 0.02554077874642858\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[1], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#OR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **세 번째 신경망 네트워크: XOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 -0.0007656919533299833\n",
      "399 -3.11181452899989e-05\n",
      "599 -1.2685581677329694e-06\n",
      "799 -1.3960657518907738e-08\n",
      "999 3.722842145670313e-09\n",
      "1199 3.722842145670313e-09\n",
      "1399 3.722842145670313e-09\n",
      "1599 3.722842145670313e-09\n",
      "1799 3.722842145670313e-09\n",
      "1999 3.722842145670313e-09\n",
      "X: [1 1] Y: [0] Output: 0.5128176286712095\n",
      "X: [1 0] Y: [1] Output: 0.5128176305326305\n",
      "X: [0 1] Y: [1] Output: 0.4999999990686774\n",
      "X: [0 0] Y: [0] Output: 0.5000000009313226\n",
      "w: tf.Tensor([ 5.1281754e-02 -7.4505806e-09], shape=(2,), dtype=float32)\n",
      "b: tf.Tensor([3.7252903e-09], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#XOR: 홀수개의 입력이 참일때만 결괏값이 참이된다\n",
    "#입력값이 2개일 떄: 2개의 입력값이 다를 때 참이된다. \n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "w = tf.random.normal([2], 0, 1)\n",
    "b = tf.random.normal([1], 0, 1)\n",
    "b_x = 1\n",
    "\n",
    "for i in range(2000):\n",
    "    error_sum = 0\n",
    "    for j in range(4):\n",
    "        output = sigmoid(np.sum(x[j] * w) + b_x * b)\n",
    "        error = y[j][0] - output\n",
    "        w = w + x[j] * 0.1 * error\n",
    "        b = b + b_x * 0.1 * error\n",
    "        error_sum += error\n",
    "        \n",
    "    if i % 200 == 199:\n",
    "        print(i, error_sum)\n",
    "        \n",
    "#XOR 네트워크 평가하기\n",
    "for i in range(4): \n",
    "    print('X:', x[i], 'Y:', y[i], 'Output:', sigmoid(np.sum(x[i]*w)+b))\n",
    "    \n",
    "#[!]에러값이 변하다가 '어느 시점'부터 변하지 않는다: \n",
    "#output을 구성하는 w와 b 출력해보기: \n",
    "print('w:', w)    #----> 첫번째 입력이 두번째 입력보다 큰 영향\n",
    "print('b:', b)    #----> 두번째 입력과 비슷하게 거의 영향이 없다\n",
    "#네트워크가 어떤 일을 하려는지 불명확함. ==>여러 개의 퍼셉트론을 사용하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#tf.keras를 이용한 XOR 네트워크 계산하기\n",
    "\n",
    "x = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 2, activation = 'sigmoid', input_shape = (2, )),\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "#model: 딥러닝 계산을 위한 여러 함수와 변수의 묶음딥러닝을 계산하는 가장 핵심적인 단위\n",
    "\n",
    "#tf.keras.Sequential: \n",
    "#model에서 가장 많이 쓰이는 구조. \n",
    "#순차적으로 뉴런과 뉴런이 합쳐진 단위(레이어)를 일직선으로 배치하는 것.\n",
    "#=시퀀셜 네트웤, 시퀀셜 모델\n",
    "#인수: 레이어가 차례대로 정의된 리스트 전달\n",
    "\n",
    "#tf.keras.layers.Dense: \n",
    "#레이어 정의 명령어. Dense는 가장 기본적인 레이어. \n",
    "#레이어 입출력 사이에 있는 모든 뉴런이 서로 연결되는 레이어. \n",
    "\n",
    "#units: 레이어를 구성하는 뉴런 수. cf.뉴런이 많을수록 레이어 성능 좋아지지만 메모리 UP\n",
    "\n",
    "#input_shape: 시퀀셜모델의 첫번쩨 레이어에서만 정의.입력의 차원 수가 어떻게 되는지 정의.\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.1), loss = 'mse')\n",
    "#optimizer: 최적화함수. 딥러닝의 학습식 정의.\n",
    "\n",
    "#SGD: 경사하강법(Stochastic Gradient Descent)\n",
    "#가중치(w)에 (입력 * 학습률 * 에러)를 더해주는 것 \n",
    "#  --손실곡선의 기울기. 손실곡선을 미분한 다음 그 값을 이용해서 가중치가 손실이 가장 낮아지는 지점에 도달하도록 반복 계산\n",
    "#  --가중치를 업데이트할 때 미분을 통해 기울기를 구한 다음 기울기가 낮은 쪽으로 업데이트하겠다! \n",
    "#'stochastic': 전체를 한번에 계산하지 않고 확률적으로 일부 샘플을 구해서 조금씩 나눠 계산하겠다!\n",
    "#cf. 구글 머신러닝 단기집중과정의 \"손실줄이기\"참고  --bit.ly/2PlcKkC\n",
    "\n",
    "#loss: error와 비슷한 개념. 손실을 줄이는 방향으로 학습. \n",
    "\n",
    "#mse: 평균제곱오차(Mean Squared Error)\n",
    "#기대출력에서 실제 출력을 뺀 뒤 제곱한 값을 평균\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'dense_4/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[-4.803235 ,  1.7984445],\n",
      "       [-4.8915677,  1.8664836]], dtype=float32)>\n",
      "<tf.Variable 'dense_4/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.9655306, -2.5677779], dtype=float32)>\n",
      "<tf.Variable 'dense_5/kernel:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[-4.990222 ],\n",
      "       [-3.4744844]], dtype=float32)>\n",
      "<tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32, numpy=array([2.1152356], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "#tf.keras를 이용한 2-레이어 XOR 네트워크 학습:\n",
    "history = model.fit(x, y, epochs=2000, batch_size = 1)\n",
    "#epochs: 훈련 데이터를 반복 학습시키는 횟수.\n",
    "#batch_size: 한번에 학습시키는 데이터 수. 각 에포크에 학습시키는 훈련 데이터의 수.\n",
    "# --1로 지정 ==> 입력을 넣었을 때 정확한 값을 출력하는지 알아보기 위해\n",
    "#첫번째, 두번째 인자로서의 x, y: 입력, 기대출력\n",
    "\n",
    "#상기 학습모델 평가하기: \n",
    "model.predict(x)\n",
    "# ==> 레이어를 추가하기 전보다 학습을 잘 하고 있다.\n",
    "#     이유: model을 구성하고 있는 파라미터(가중치, 편향) 확인해보기: \n",
    "for weight in model.weights: \n",
    "    print(weight)\n",
    "#model.weights: 가중치정보가 저장되어 있는 곳. \n",
    "#kernel: 입력-레이어, 레이어-레이어 사이의 뉴런을 연결할 때 사용되는 가중치\n",
    "#bias: 편향과 연결된 가중치\n",
    "#가중치들을 그래프로 나타내보면 레이어 추가 전보다 가중치들이 무슨 일을 하는지 가시적이지 않음. \n",
    "# --> 가중치시각화보다 네트워크의 학습상황을 더 잘 파악할 수있는 방법 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
